{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "057f3a1d",
      "metadata": {
        "id": "057f3a1d"
      },
      "source": [
        "# ANN and CNN modeling - NestedCV preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s4ru5YGRyjuG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4ru5YGRyjuG",
        "outputId": "940da01a-b74b-41c0-e3d3-d1530a6c6dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sEDfIBGrfWtJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEDfIBGrfWtJ",
        "outputId": "af657ad7-07b4-4ca2-f90f-e38158078d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras_tuner) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "%pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v22PjQKjw4hZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v22PjQKjw4hZ",
        "outputId": "8f7ba8e5-e307-44f7-dbd4-33f371b3d263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22a3b5d1",
      "metadata": {
        "id": "22a3b5d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, BatchNormalization,\n",
        "                                   Dropout, Dense, Flatten,\n",
        "                                   Input, Concatenate)\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca90a5e5",
      "metadata": {
        "id": "ca90a5e5"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49f8efc1",
      "metadata": {
        "id": "49f8efc1"
      },
      "outputs": [],
      "source": [
        "#X_images = np.load(r'C:\\Users\\andre\\Desktop\\Stage 2A\\Projet\\preprocessed_data\\nv_mel_ratio\\X_segmented.npy', allow_pickle=True)\n",
        "X_align = np.load(r'/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/nv_mel_pca/X_align.npy', allow_pickle=True)\n",
        "masks = np.load(r'/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/nv_mel_pca/masks.npy', allow_pickle=True)\n",
        "y = np.load(r'/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/nv_mel_pca/y.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7MjcqLrSmm6k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MjcqLrSmm6k",
        "outputId": "5f2bf81d-9f83-43bc-ea87-67d01a45653c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7793, 450, 600)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masks.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3213469",
      "metadata": {
        "id": "a3213469"
      },
      "source": [
        "## Create NN with shape information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fc37bc",
      "metadata": {
        "id": "b4fc37bc"
      },
      "outputs": [],
      "source": [
        "y_encoded = np.abs(np.ones(y.shape) - LabelEncoder().fit_transform(y)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WEqFSOGQrQjn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEqFSOGQrQjn",
        "outputId": "256d1765-374e-4e1c-d500-59fb811cf4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Mapping: 'nv': 0, 'mel': 1\n"
          ]
        }
      ],
      "source": [
        "if len(y_encoded[y_encoded==1]) > len(y_encoded[y_encoded==0]):\n",
        "  print(\"Label Mapping: 'nv': 1, 'mel': 0\")\n",
        "else:\n",
        "  print(\"Label Mapping: 'nv': 0, 'mel': 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WWqzBidw1Nbv",
      "metadata": {
        "id": "WWqzBidw1Nbv"
      },
      "outputs": [],
      "source": [
        "def calculate_class_weights(y):\n",
        "    #Calculate weights\n",
        "    weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(y),\n",
        "        y=y\n",
        "    )\n",
        "    #Create dictionary mapping class indices to weights\n",
        "    class_weights = dict(zip(range(len(weights)), weights))\n",
        "    return class_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pFbUtmQT1cpu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFbUtmQT1cpu",
        "outputId": "a60d7cec-203c-4aef-c8c2-37c18aefc9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: np.float64(0.5829593058049073), 1: np.float64(3.5135256988277725)}\n"
          ]
        }
      ],
      "source": [
        "print(calculate_class_weights(y_encoded))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c45da8ce",
      "metadata": {
        "id": "c45da8ce"
      },
      "source": [
        "# Define model spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JdQinMqNQHZE",
      "metadata": {
        "id": "JdQinMqNQHZE"
      },
      "source": [
        "## CNN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4d91b3",
      "metadata": {
        "id": "0f4d91b3"
      },
      "outputs": [],
      "source": [
        "def build_cnn_model(hp):\n",
        "    num_layers = hp.Int('num_layers', 2, 4)\n",
        "    l2_reg = hp.Float('reg', 1e-4, 1e-2, sampling='log')\n",
        "    lr = hp.Float('learning_rate', 0.0005, 0.002, sampling='log')\n",
        "    dropout_rate = hp.Float('dropout_rate', 0.1, 0.4, step=0.1)\n",
        "    inputs = tf.keras.layers.Input(shape=(masks.shape[1], masks.shape[2], 1))\n",
        "    x = inputs\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        units = hp.Choice(f'filter_units_{i}', [16, 32, 64])\n",
        "        x = tf.keras.layers.Conv2D(filters=units, kernel_size=(3, 3), activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "    #Dense layers\n",
        "    num_layers_dense = hp.Int('num_layers_dense', 1, 3)\n",
        "    dropout_dense = hp.Float('dropout_dense', 0.1, 0.4, step=0.1)\n",
        "\n",
        "    for i in range(num_layers_dense):\n",
        "        units = hp.Choice(f'dense_units_{i}', [32, 64, 128])\n",
        "        x = tf.keras.layers.Dense(units, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_dense)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4lfXZ7fgQKzK",
      "metadata": {
        "id": "4lfXZ7fgQKzK"
      },
      "source": [
        "## ANN models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YPe-FAbhQNFI",
      "metadata": {
        "id": "YPe-FAbhQNFI"
      },
      "outputs": [],
      "source": [
        "def build_ann_model(hp):\n",
        "    num_layers = hp.Int('num_layers', 1, 3)\n",
        "    l2_reg = hp.Float('l2_reg', 1e-4, 1e-2, sampling='log')\n",
        "    dropout_rate = hp.Float('dropout_rate', 0.1, 0.4, step=0.1)\n",
        "    lr = hp.Float('learning_rate', 0.0005, 0.002, sampling='log')\n",
        "    inputs = tf.keras.layers.Input(shape=(X_align.shape[1],))\n",
        "    x = inputs\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        units = hp.Choice(f'dense_units_{i}', [16, 32, 64, 128])\n",
        "        x = tf.keras.layers.Dense(units, activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcfdd116",
      "metadata": {
        "id": "dcfdd116"
      },
      "source": [
        "# Model robust evaluation - Nested Stratified KFold CV with BayesianOptimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HYA3fKQ2I2lR",
      "metadata": {
        "id": "HYA3fKQ2I2lR"
      },
      "outputs": [],
      "source": [
        "CNN_metrics = {'auc': [], 'balanced_accuracy': [], 'f1': [], 'training_time':[], 'FPR':[], 'TPR':[], 'Threshold':[]}\n",
        "ANN_metrics = {'auc': [], 'balanced_accuracy': [], 'f1': [], 'training_time':[], 'FPR':[], 'TPR':[], 'Threshold':[]}\n",
        "best_hps_CNN_per_fold = []\n",
        "best_hps_ANN_per_fold = []\n",
        "execution_time_CNN = 0\n",
        "execution_time_ANN = 0\n",
        "n_inner_splits = 2\n",
        "n_outer_splits = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpAewFyxCg0h",
      "metadata": {
        "id": "hpAewFyxCg0h"
      },
      "source": [
        "## define CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_2DjRU6qMYI1",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2DjRU6qMYI1",
        "outputId": "b2935844-2426-413b-d135-16c835e6b127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 02m 13s]\n",
            "val_auc: 0.7151142358779907\n",
            "\n",
            "Best val_auc So Far: 0.7295193076133728\n",
            "Total elapsed time: 00h 17m 29s\n",
            "Fold interne 2/2\n",
            "Évaluation des configs sur fold interne 2\n",
            "  CNN config 1/10\n",
            "  CNN config 2/10\n",
            "  CNN config 3/10\n",
            "  CNN config 4/10\n",
            "  CNN config 5/10\n",
            "  CNN config 6/10\n",
            "  CNN config 7/10\n",
            "  CNN config 8/10\n",
            "  CNN config 9/10\n",
            "  CNN config 10/10\n",
            "  ANN config 1/10\n",
            "  ANN config 2/10\n",
            "  ANN config 3/10\n",
            "  ANN config 4/10\n",
            "  ANN config 5/10\n",
            "  ANN config 6/10\n",
            "  ANN config 7/10\n",
            "  ANN config 8/10\n",
            "  ANN config 9/10\n",
            "  ANN config 10/10\n",
            "Entraînement final sur tout le train externe...\n",
            "Epoch 1/50\n",
            "232/232 - 29s - 124ms/step - auc: 0.6275 - loss: 2.7453 - val_auc: 0.6562 - val_loss: 1.6917\n",
            "Epoch 2/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.6629 - loss: 1.7020 - val_auc: 0.5231 - val_loss: 1.2881\n",
            "Epoch 3/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.6926 - loss: 1.3421 - val_auc: 0.5248 - val_loss: 1.0060\n",
            "Epoch 4/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7154 - loss: 1.1805 - val_auc: 0.6909 - val_loss: 0.8640\n",
            "Epoch 5/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7251 - loss: 1.1193 - val_auc: 0.7623 - val_loss: 0.8435\n",
            "Epoch 6/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7346 - loss: 1.0288 - val_auc: 0.4099 - val_loss: 0.7545\n",
            "Epoch 7/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7304 - loss: 1.0279 - val_auc: 0.7770 - val_loss: 0.7636\n",
            "Epoch 8/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7322 - loss: 1.0393 - val_auc: 0.6707 - val_loss: 1.0529\n",
            "Epoch 9/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7392 - loss: 1.0599 - val_auc: 0.3948 - val_loss: 0.7757\n",
            "Epoch 10/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7361 - loss: 1.0402 - val_auc: 0.6320 - val_loss: 0.8474\n",
            "Epoch 11/50\n",
            "232/232 - 6s - 27ms/step - auc: 0.7385 - loss: 1.1079 - val_auc: 0.6020 - val_loss: 0.9546\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
            "Epoch 1/50\n",
            "232/232 - 10s - 43ms/step - auc: 0.5283 - loss: 0.8989 - val_auc: 0.6363 - val_loss: 0.6883\n",
            "Epoch 2/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.5416 - loss: 0.8313 - val_auc: 0.6208 - val_loss: 0.6555\n",
            "Epoch 3/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.5443 - loss: 0.7994 - val_auc: 0.6332 - val_loss: 0.6352\n",
            "Epoch 4/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.5666 - loss: 0.7726 - val_auc: 0.6446 - val_loss: 0.6175\n",
            "Epoch 5/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.5883 - loss: 0.7538 - val_auc: 0.6557 - val_loss: 0.6044\n",
            "Epoch 6/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6058 - loss: 0.7342 - val_auc: 0.6592 - val_loss: 0.6220\n",
            "Epoch 7/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6315 - loss: 0.7177 - val_auc: 0.6639 - val_loss: 0.6065\n",
            "Epoch 8/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6152 - loss: 0.7278 - val_auc: 0.6650 - val_loss: 0.5953\n",
            "Epoch 9/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6449 - loss: 0.7064 - val_auc: 0.6567 - val_loss: 0.5995\n",
            "Epoch 10/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6679 - loss: 0.6950 - val_auc: 0.6563 - val_loss: 0.6069\n",
            "Epoch 11/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6745 - loss: 0.6905 - val_auc: 0.6700 - val_loss: 0.5813\n",
            "Epoch 12/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6927 - loss: 0.6767 - val_auc: 0.6737 - val_loss: 0.5799\n",
            "Epoch 13/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.6981 - loss: 0.6718 - val_auc: 0.6604 - val_loss: 0.5800\n",
            "Epoch 14/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7105 - loss: 0.6663 - val_auc: 0.6582 - val_loss: 0.5765\n",
            "Epoch 15/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7188 - loss: 0.6597 - val_auc: 0.6508 - val_loss: 0.5714\n",
            "Epoch 16/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7306 - loss: 0.6508 - val_auc: 0.6577 - val_loss: 0.5564\n",
            "Epoch 17/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7371 - loss: 0.6453 - val_auc: 0.6688 - val_loss: 0.5547\n",
            "Epoch 18/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7544 - loss: 0.6333 - val_auc: 0.6664 - val_loss: 0.5331\n",
            "Epoch 19/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7532 - loss: 0.6329 - val_auc: 0.6629 - val_loss: 0.5220\n",
            "Epoch 20/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7754 - loss: 0.6120 - val_auc: 0.6614 - val_loss: 0.5115\n",
            "Epoch 21/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7610 - loss: 0.6239 - val_auc: 0.6598 - val_loss: 0.5106\n",
            "Epoch 22/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7876 - loss: 0.6004 - val_auc: 0.6653 - val_loss: 0.4936\n",
            "Epoch 23/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7901 - loss: 0.5964 - val_auc: 0.6592 - val_loss: 0.4872\n",
            "Epoch 24/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.7975 - loss: 0.5873 - val_auc: 0.6573 - val_loss: 0.4830\n",
            "Epoch 25/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8022 - loss: 0.5835 - val_auc: 0.6570 - val_loss: 0.4796\n",
            "Epoch 26/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8138 - loss: 0.5660 - val_auc: 0.6493 - val_loss: 0.4672\n",
            "Epoch 27/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8150 - loss: 0.5664 - val_auc: 0.6505 - val_loss: 0.4670\n",
            "Epoch 28/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8305 - loss: 0.5475 - val_auc: 0.6444 - val_loss: 0.4612\n",
            "Epoch 29/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8263 - loss: 0.5516 - val_auc: 0.6315 - val_loss: 0.4630\n",
            "Epoch 30/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8318 - loss: 0.5425 - val_auc: 0.6379 - val_loss: 0.4535\n",
            "Epoch 31/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8421 - loss: 0.5314 - val_auc: 0.6303 - val_loss: 0.4537\n",
            "Epoch 32/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8445 - loss: 0.5264 - val_auc: 0.6264 - val_loss: 0.4539\n",
            "Epoch 33/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8592 - loss: 0.5056 - val_auc: 0.6295 - val_loss: 0.4536\n",
            "Epoch 34/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8562 - loss: 0.5083 - val_auc: 0.6463 - val_loss: 0.4451\n",
            "Epoch 35/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8609 - loss: 0.5000 - val_auc: 0.6520 - val_loss: 0.4492\n",
            "Epoch 36/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8718 - loss: 0.4835 - val_auc: 0.6491 - val_loss: 0.4610\n",
            "Epoch 37/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8764 - loss: 0.4759 - val_auc: 0.6477 - val_loss: 0.4432\n",
            "Epoch 38/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8770 - loss: 0.4736 - val_auc: 0.6431 - val_loss: 0.4537\n",
            "Epoch 39/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8788 - loss: 0.4711 - val_auc: 0.6350 - val_loss: 0.4533\n",
            "Epoch 40/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8886 - loss: 0.4536 - val_auc: 0.6242 - val_loss: 0.4738\n",
            "Epoch 41/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8850 - loss: 0.4604 - val_auc: 0.6226 - val_loss: 0.4747\n",
            "Epoch 42/50\n",
            "232/232 - 1s - 3ms/step - auc: 0.8902 - loss: 0.4501 - val_auc: 0.6195 - val_loss: 0.4827\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "DONE\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
        "\n",
        "#define stratified splits\n",
        "skf_external = StratifiedKFold(n_splits=n_outer_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "for fold_idx, (train_idx, test_idx) in enumerate(skf_external.split(masks, y)):\n",
        "    if fold_idx >= 4: #split the work between 3 notebooks\n",
        "      continue\n",
        "    print(f\"Fold externe {fold_idx+1}/20\")\n",
        "    X_train_CNN, X_test_CNN = masks[train_idx], masks[test_idx]\n",
        "    X_train_ANN, X_test_ANN = X_align[train_idx], X_align[test_idx]\n",
        "    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
        "\n",
        "    #we clear memory at the start of each external fold\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    #Inner tuner (RandomSearch optimization)\n",
        "    start_CNN = time.time()\n",
        "\n",
        "    tuner_CNN = kt.RandomSearch(\n",
        "        build_cnn_model,\n",
        "        objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
        "        max_trials=10,\n",
        "        seed = seed + fold_idx,\n",
        "        overwrite=True,\n",
        "        directory=f'tuner_cnn_fold_{fold_idx}',  # Dossier unique par fold\n",
        "        project_name='cnn_search'\n",
        "    )\n",
        "    end_CNN = time.time()\n",
        "    execution_time_CNN += end_CNN - start_CNN\n",
        "\n",
        "    start_ANN = time.time()\n",
        "    tuner_ANN = kt.RandomSearch(\n",
        "        build_ann_model,\n",
        "        objective=kt.Objective(\"val_auc\", direction=\"max\"),\n",
        "        max_trials=10,\n",
        "        seed = seed + fold_idx,\n",
        "        overwrite=True,\n",
        "        directory=f'tuner_ann_fold_{fold_idx}',  # Dossier unique par fold\n",
        "        project_name='ann_search'\n",
        "    )\n",
        "    end_ANN = time.time()\n",
        "    execution_time_ANN += end_ANN - start_ANN\n",
        "\n",
        "    #define inner CV\n",
        "    skf_internal = StratifiedKFold(n_splits=n_inner_splits, shuffle=True, random_state=seed)\n",
        "    #sauvegarde des métriques\n",
        "    ann_auc_inner = [[] for _ in range(n_inner_splits)]\n",
        "    cnn_auc_inner = [[] for _ in range(n_inner_splits)]\n",
        "\n",
        "    for inner_fold_idx, (inner_train_idx, inner_val_idx) in enumerate(skf_internal.split(X_train_CNN, y_train)):\n",
        "        print(f\"Fold interne {inner_fold_idx+1}/2\")\n",
        "        X_inner_train_CNN, X_inner_val_CNN = X_train_CNN[inner_train_idx], X_train_CNN[inner_val_idx]\n",
        "        X_inner_train_ANN, X_inner_val_ANN = X_train_ANN[inner_train_idx], X_train_ANN[inner_val_idx]\n",
        "        y_inner_train, y_inner_val = y_train[inner_train_idx], y_train[inner_val_idx]\n",
        "\n",
        "        # standardize data\n",
        "        start_ANN = time.time()\n",
        "        scaler = StandardScaler()\n",
        "        X_inner_train_ANN = scaler.fit_transform(X_inner_train_ANN)\n",
        "        X_inner_val_ANN = scaler.transform(X_inner_val_ANN)\n",
        "\n",
        "\n",
        "        # class weights\n",
        "        start_CNN = time.time()\n",
        "        class_weights_inner_train = calculate_class_weights(y_inner_train)\n",
        "        end = time.time()\n",
        "        execution_time_ANN += end - start_ANN\n",
        "        execution_time_CNN += end - start_CNN\n",
        "\n",
        "        # Recherche sur inner folds lors de la PREMIERE itération\n",
        "        if inner_fold_idx == 0:\n",
        "            print(\"Recherche des hyperparamètres...\")\n",
        "\n",
        "            # ANN\n",
        "            start_ANN = time.time()\n",
        "            tuner_ANN.search(\n",
        "                X_inner_train_ANN, y_inner_train,\n",
        "                validation_data=(X_inner_val_ANN, y_inner_val),\n",
        "                epochs=50,\n",
        "                batch_size=32,\n",
        "                class_weight=class_weights_inner_train,\n",
        "                callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "                verbose=2\n",
        "            )\n",
        "\n",
        "            end = time.time()\n",
        "            execution_time_ANN += end - start_ANN\n",
        "\n",
        "            # Clear après ANN\n",
        "            tf.keras.backend.clear_session()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "            # CNN\n",
        "            start_CNN = time.time()\n",
        "            tuner_CNN.search(\n",
        "                X_inner_train_CNN, y_inner_train,\n",
        "                validation_data=(X_inner_val_CNN, y_inner_val),\n",
        "                epochs=50,\n",
        "                batch_size=32,\n",
        "                class_weight=class_weights_inner_train,\n",
        "                callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "                verbose=2\n",
        "            )\n",
        "            end = time.time()\n",
        "            execution_time_CNN += end - start_CNN\n",
        "\n",
        "            # on récupère tous les configurations explorées\n",
        "            all_trials_CNN = tuner_CNN.oracle.trials.copy()  # Copie pour éviter références\n",
        "            all_trials_ANN = tuner_ANN.oracle.trials.copy()\n",
        "\n",
        "            # Mem clear\n",
        "            del tuner_CNN\n",
        "            del tuner_ANN\n",
        "            tf.keras.backend.clear_session()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "            # on sauvegarde l'auc pour chacune des configurations\n",
        "            for _, trial in all_trials_CNN.items():\n",
        "                cnn_auc_inner[inner_fold_idx].append(trial.score)\n",
        "            for _, trial in all_trials_ANN.items():\n",
        "                ann_auc_inner[inner_fold_idx].append(trial.score)\n",
        "\n",
        "        # lors des itérations suivantes\n",
        "        else:\n",
        "            print(f\"Évaluation des configs sur fold interne {inner_fold_idx+1}\")\n",
        "\n",
        "            # CNN d'abord\n",
        "            for i, trial in enumerate(all_trials_CNN.values()):\n",
        "                print(f\"  CNN config {i+1}/{len(all_trials_CNN)}\")\n",
        "                hp = kt.engine.hyperparameters.HyperParameters()\n",
        "                for k, v in trial.hyperparameters.values.items():\n",
        "                    hp.Fixed(k, v)\n",
        "\n",
        "                # Construire et entraîner\n",
        "                start_CNN = time.time()\n",
        "                model_cnn = build_cnn_model(hp)\n",
        "                model_cnn.fit(\n",
        "                    X_inner_train_CNN, y_inner_train,\n",
        "                    validation_data=(X_inner_val_CNN, y_inner_val),\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    class_weight=class_weights_inner_train,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "                    verbose=0  # Moins verbose pour clarté\n",
        "                )\n",
        "\n",
        "                # Évaluation\n",
        "                score = model_cnn.evaluate(X_inner_val_CNN, y_inner_val, verbose=0)[1]\n",
        "                cnn_auc_inner[inner_fold_idx].append(score)\n",
        "                end = time.time()\n",
        "                execution_time_CNN += end - start_CNN\n",
        "\n",
        "                # CRUCIAL: Libérer la mémoire immédiatement\n",
        "                del model_cnn\n",
        "                tf.keras.backend.clear_session()\n",
        "                gc.collect()\n",
        "\n",
        "            # ANN ensuite\n",
        "            for i, trial in enumerate(all_trials_ANN.values()):\n",
        "                print(f\"  ANN config {i+1}/{len(all_trials_ANN)}\")\n",
        "                hp = kt.engine.hyperparameters.HyperParameters()\n",
        "                for k, v in trial.hyperparameters.values.items():\n",
        "                    hp.Fixed(k, v)\n",
        "\n",
        "                # Construire et entraîner\n",
        "                start_ANN = time.time()\n",
        "                model_ann = build_ann_model(hp)\n",
        "                model_ann.fit(\n",
        "                    X_inner_train_ANN, y_inner_train,\n",
        "                    validation_data=(X_inner_val_ANN, y_inner_val),\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    class_weight=class_weights_inner_train,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
        "                    verbose=0\n",
        "                )\n",
        "\n",
        "                # Évaluation\n",
        "                score = model_ann.evaluate(X_inner_val_ANN, y_inner_val, verbose=0)[1]\n",
        "                ann_auc_inner[inner_fold_idx].append(score)\n",
        "                end = time.time()\n",
        "                execution_time_ANN += end - start_ANN\n",
        "\n",
        "                # CRUCIAL: Libérer la mémoire immédiatement\n",
        "                del model_ann\n",
        "                tf.keras.backend.clear_session()\n",
        "                gc.collect()\n",
        "\n",
        "\n",
        "    #Calcul de la moyenne des auc\n",
        "    ann_auc_inner = np.array(ann_auc_inner)\n",
        "    cnn_auc_inner = np.array(cnn_auc_inner)\n",
        "    ann_auc_mean = np.mean(ann_auc_inner, axis=0)\n",
        "    cnn_auc_mean = np.mean(cnn_auc_inner, axis=0)\n",
        "\n",
        "    ### - On récupère la meilleure config d'hyperparamètres trouvée - ###\n",
        "    #CNN\n",
        "    start_CNN = time.time()\n",
        "    best_auc_cnn = -1\n",
        "    best_hp_cnn = None\n",
        "    for trial_id, auc_score in zip(all_trials_CNN.keys(), cnn_auc_mean):\n",
        "        if auc_score > best_auc_cnn:\n",
        "            best_auc_cnn = auc_score\n",
        "            best_hp_cnn = all_trials_CNN[trial_id].hyperparameters\n",
        "    end = time.time()\n",
        "    execution_time_CNN += end - start_CNN\n",
        "\n",
        "    #ANN\n",
        "    start_ANN = time.time()\n",
        "    best_auc_ann = -1\n",
        "    best_hp_ann = None\n",
        "    for trial_id, auc_score in zip(all_trials_ANN.keys(), ann_auc_mean):\n",
        "        if auc_score > best_auc_ann:\n",
        "            best_auc_ann = auc_score\n",
        "            best_hp_ann = all_trials_ANN[trial_id].hyperparameters\n",
        "    end = time.time()\n",
        "    execution_time_ANN += end - start_ANN\n",
        "\n",
        "    # Sauvegarde de ces hyperparamètres\n",
        "    best_hps_CNN_per_fold.append(best_hp_cnn.values)\n",
        "    best_hps_ANN_per_fold.append(best_hp_ann.values)\n",
        "\n",
        "    #IMPORTANT: Nettoyer les tuners avant l'entraînement final\n",
        "    del all_trials_CNN\n",
        "    del all_trials_ANN\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"Entraînement final sur tout le train externe...\")\n",
        "\n",
        "    #Training sur tout le train externe avec les meilleurs hps\n",
        "    start = time.time()\n",
        "    class_weights_train = calculate_class_weights(y_train)\n",
        "    end = time.time()\n",
        "    execution_time_ANN += end - start\n",
        "    execution_time_CNN += end - start\n",
        "\n",
        "    # Évaluation sur le test externe\n",
        "    class_weights_external_test = calculate_class_weights(y_test)\n",
        "    sample_weights_external_test = np.array([class_weights_external_test[y_val] for y_val in y_test])\n",
        "\n",
        "    #CNN\n",
        "    start = time.time()\n",
        "    model_cnn_final = build_cnn_model(best_hp_cnn)\n",
        "    model_cnn_final.fit(\n",
        "        X_train_CNN, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test_CNN, y_test),\n",
        "        callbacks=[\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                mode='min',\n",
        "                restore_best_weights=True,\n",
        "                verbose=0\n",
        "            )\n",
        "        ],\n",
        "        class_weight=class_weights_train,\n",
        "        verbose=2\n",
        "    )\n",
        "    y_pred_proba = model_cnn_final.predict(X_test_CNN)\n",
        "    y_pred = np.where(y_pred_proba > 0.5, 1, 0).flatten()\n",
        "\n",
        "    #AUC_CNN\n",
        "    auc_CNN = model_cnn_final.evaluate(X_test_CNN, y_test, verbose=0)[1]\n",
        "    #Balanced_accuracy_CNN\n",
        "    balanced_accuracy_CNN = balanced_accuracy_score(y_test, y_pred, sample_weight=sample_weights_external_test)\n",
        "    #f1_score\n",
        "    f1_CNN = f1_score(y_test, y_pred, average='weighted')\n",
        "    #ROC_CNN\n",
        "    roc_curve_CNN = roc_curve(y_test, y_pred_proba)\n",
        "    fpr_CNN, tpr_CNN, thresholds_CNN = roc_curve_CNN\n",
        "\n",
        "    end = time.time()\n",
        "    execution_time_CNN += end - start\n",
        "    CNN_metrics['training_time'].append(end - start)\n",
        "\n",
        "    #Standardise les features pour l'ANN\n",
        "    start_ANN = time.time()\n",
        "    scaler = StandardScaler()\n",
        "    X_train_ANN_scaled = scaler.fit_transform(X_train_ANN)\n",
        "    X_test_ANN_scaled = scaler.transform(X_test_ANN)\n",
        "\n",
        "    #ANN\n",
        "    model_ann_final = build_ann_model(best_hp_ann)\n",
        "    model_ann_final.fit(\n",
        "        X_train_ANN_scaled, y_train,\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        validation_data=(X_test_ANN_scaled, y_test),\n",
        "        callbacks=[\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=5,\n",
        "                mode='min',\n",
        "                restore_best_weights=True,\n",
        "                verbose=0\n",
        "            )\n",
        "        ],\n",
        "        class_weight=class_weights_train,\n",
        "        verbose=2\n",
        "      )\n",
        "    y_pred_proba = model_ann_final.predict(X_test_ANN_scaled)\n",
        "    y_pred = np.where(y_pred_proba > 0.5, 1, 0).flatten()\n",
        "    #AUC_ANN\n",
        "    auc_ANN = model_ann_final.evaluate(X_test_ANN_scaled, y_test, verbose=0)[1]\n",
        "    #Balanced_accuracy_ANN\n",
        "    balanced_accuracy_ANN = balanced_accuracy_score(y_test, y_pred, sample_weight=sample_weights_external_test)\n",
        "    #f1_ANN\n",
        "    f1_ANN = f1_score(y_test, y_pred, average='weighted')\n",
        "    #ROC_ANN\n",
        "    roc_curve_ANN = roc_curve(y_test, y_pred_proba)\n",
        "    fpr_ANN, tpr_ANN, thresholds_ANN = roc_curve_ANN\n",
        "\n",
        "    end = time.time()\n",
        "    execution_time_ANN += end - start_ANN\n",
        "    ANN_metrics['training_time'].append(end - start_ANN)\n",
        "\n",
        "\n",
        "\n",
        "    #### - CNN metrics - ####\n",
        "\n",
        "    CNN_metrics['auc'].append(auc_CNN)\n",
        "    CNN_metrics['balanced_accuracy'].append(balanced_accuracy_CNN)\n",
        "    CNN_metrics['f1'].append(f1_CNN)\n",
        "    CNN_metrics['FPR'].append(fpr_CNN)\n",
        "    CNN_metrics['TPR'].append(tpr_CNN)\n",
        "    CNN_metrics['Threshold'].append(thresholds_CNN)\n",
        "\n",
        "    #### - ANN metrics - ####\n",
        "\n",
        "    ANN_metrics['auc'].append(auc_ANN)\n",
        "    ANN_metrics['balanced_accuracy'].append(balanced_accuracy_ANN)\n",
        "    ANN_metrics['f1'].append(f1_ANN)\n",
        "    ANN_metrics['FPR'].append(fpr_ANN)\n",
        "    ANN_metrics['TPR'].append(tpr_ANN)\n",
        "    ANN_metrics['Threshold'].append(thresholds_ANN)\n",
        "\n",
        "    #Nettoyer après chaque fold externe\n",
        "    del model_cnn_final\n",
        "    del model_ann_final\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "# Sauvegarde finale des résultats\n",
        "df_CNN_metrics = pd.DataFrame(CNN_metrics)\n",
        "df_ANN_metrics = pd.DataFrame(ANN_metrics)\n",
        "\n",
        "df_CNN_metrics.to_csv(\"/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/CNN_metrics_1-4.csv\", index=False)\n",
        "df_ANN_metrics.to_csv(\"/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/ANN_metrics_1-4.csv\", index=False)\n",
        "\n",
        "pd.DataFrame(best_hps_CNN_per_fold).to_csv(\"/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/best_hps_CNN_1-4.csv\", index=False)\n",
        "pd.DataFrame(best_hps_ANN_per_fold).to_csv(\"/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/best_hps_ANN_1-4.csv\", index=False)\n",
        "\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nvpiHP6Fpama",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nvpiHP6Fpama",
        "outputId": "c7bd678f-992e-47b3-8db3-56416f138471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temps d'execution CNN : 9741.59652686119 secondes\n",
            "Temps d'execution ANN : 2049.7476539611816 secondes\n"
          ]
        }
      ],
      "source": [
        "print(f\"Temps d'execution CNN : {execution_time_CNN} secondes\")\n",
        "print(f\"Temps d'execution ANN : {execution_time_ANN} secondes\")\n",
        "\n",
        "#save those times\n",
        "with open('/content/drive/MyDrive/Stage 2A/ANN_CNN_comparison_PCA/execution_time_1.txt', 'w') as f:\n",
        "    f.write(\"CNN \" + str(execution_time_CNN) + 's')\n",
        "    f.write('\\n')\n",
        "    f.write(\"ANN \" + str(execution_time_ANN) + 's')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}